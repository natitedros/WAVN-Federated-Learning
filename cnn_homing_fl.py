# -*- coding: utf-8 -*-
"""CNN_Homing_FL.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10GgVXWGop2eS-JXyL1BvFOQXGpuFo63e
"""

from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf
import pandas as pd
import numpy as np
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from sklearn.model_selection import train_test_split

CSV_PATH = '/content/drive/MyDrive/gazebo_dataset_fl/labels.csv'
IMG_DIR = '/content/drive/MyDrive/gazebo_dataset_fl/images/'

df = pd.read_csv(CSV_PATH)
print(f"Total samples: {len(df)}")
print(f"\nFirst few rows:\n{df.head()}")
print(f"\nDirection counts:\n{df['direction'].value_counts()}")

direction_map = {'forward': 0, 'backward': 1, 'left': 2, 'right': 3}
df['direction_label'] = df['direction'].map(direction_map)
num_clients = 4
shard_size = len(df) // num_clients

client_datasets = []
for i in range(num_clients):
    start = i * shard_size
    end = start + shard_size
    shard = df.iloc[start:end]

    # For each shard create train/val split
    train_df, val_df = train_test_split(shard, test_size=0.2, random_state=42)

    client_datasets.append((train_df, val_df))
    print(f"\nClient: {i+1}")
    print(f"Training samples: {len(train_df)}")
    print(f"Validation samples: {len(val_df)}")

# Function to load image
def load_image(img_path):
    img = load_img(IMG_DIR + img_path, target_size=(224, 224))
    img = img_to_array(img) / 255.0  # Normalize to [0, 1]
    return img

# Creating the dataset
def create_dataset(dataframe, batch_size=32):
    current_images = []
    dest_images = []
    labels = []

    for idx, row in dataframe.iterrows():
        current_img = load_image(row['current_image'])
        dest_img = load_image(row['destination_image'])

        current_images.append(current_img)
        dest_images.append(dest_img)
        labels.append(row['direction_label'])

    current_images = np.array(current_images)
    dest_images = np.array(dest_images)
    labels = np.array(labels)

    return current_images, dest_images, labels

for i, (train_df, val_df) in enumerate(client_datasets):

  print(f"\nClient: {i+1}")
  print("Loading training data...")
  X_train_current, X_train_dest, y_train = create_dataset(train_df)

  print("Loading validation data...")
  X_val_current, X_val_dest, y_val = create_dataset(val_df)

  print(f"\nTraining data shapes:")
  print(f"Current images: {X_train_current.shape}")
  print(f"Destination images: {X_train_dest.shape}")
  print(f"Labels: {y_train.shape}")

from tensorflow.keras import layers, models

def create_model(num_classes=4):
    # Input for current image
    current_input = layers.Input(shape=(224, 224, 3), name='current_image')

    # Input for destination image
    dest_input = layers.Input(shape=(224, 224, 3), name='destination_image')

    # Shared CNN layers
    def cnn_branch(x):
        x = layers.Conv2D(32, (3, 3), activation='relu')(x)
        x = layers.MaxPooling2D((2, 2))(x)
        x = layers.Conv2D(64, (3, 3), activation='relu')(x)
        x = layers.MaxPooling2D((2, 2))(x)
        x = layers.Conv2D(64, (3, 3), activation='relu')(x)
        x = layers.MaxPooling2D((2, 2))(x)
        x = layers.Flatten()(x)
        return x

    # Process both images
    current_features = cnn_branch(current_input)
    dest_features = cnn_branch(dest_input)

    # Combine features
    combined = layers.concatenate([current_features, dest_features])

    # Dense layers
    x = layers.Dense(128, activation='relu')(combined)
    x = layers.Dropout(0.5)(x)
    output = layers.Dense(num_classes, activation='softmax')(x)

    # Create model
    model = models.Model(inputs=[current_input, dest_input], outputs=output)

    return model

model = []
for i in range(num_clients):
    model.append(create_model(num_classes=4))
model[0].summary()

for i in range(num_clients):
    model[i].compile(optimizer='adam',
                      loss='sparse_categorical_crossentropy',
                      metrics=['accuracy'])

# Training the model
# batch size is the number of data instances to train at once before updating the weights
# not related with pixel size. Usually assigned powers of 2 numbers for hardware efficiency
for i in range(num_clients):
    print(f"\nTraining client {i+1}...")
    history = model[i].fit(
        [X_train_current, X_train_dest],
        y_train,
        validation_data=([X_val_current, X_val_dest], y_val),
        epochs=5,
        batch_size=32
    )

# Getting the weights
w0 = model[0].get_weights()
w1 = model[1].get_weights()
w2 = model[2].get_weights()
w3 = model[3].get_weights()

print(f"w0: {len(w0)} arrays with shapes: {[w.shape for w in w0]}")
print(f"w1: {len(w1)} arrays with shapes: {[w.shape for w in w1]}")
print(f"w2: {len(w2)} arrays with shapes: {[w.shape for w in w2]}")
print(f"w3: {len(w3)} arrays with shapes: {[w.shape for w in w3]}")

pairwise_dist = np.array([w0, w1, w2, w3], dtype=object)

# Performing the federated averaging
avg_weights = np.average(pairwise_dist, axis=0)
print(f"Average Weight: {len(avg_weights)} arrays with shapes: {[w.shape for w in avg_weights]}")

# Create a new model with the same architecture as model[0]
avg_model = create_model()

avg_model.set_weights(avg_weights)

# Save the model
avg_model.save('/content/drive/MyDrive/Models/navigation_model_fl.h5')
print("\nModel saved to Google Drive!")

# Step 14: Function to test specific image pairs
def test_prediction(current_img_name, dest_img_name):
    """
    Test prediction for specific images by name
    Using the average model
    Args:
        current_img_name: Name of current image (e.g., 'current_001.jpg')
        dest_img_name: Name of destination image (e.g., 'destination_015.jpg')
    """
    direction_names = {0: 'forward', 1: 'backward', 2: 'left', 3: 'right'}

    # Load the images
    current_img = load_image(current_img_name)
    dest_img = load_image(dest_img_name)

    # Add batch dimension
    current_img = np.expand_dims(current_img, axis=0)
    dest_img = np.expand_dims(dest_img, axis=0)

    # Make prediction
    prediction = avg_model.predict([current_img, dest_img], verbose=0)
    predicted_label = np.argmax(prediction)
    confidence = prediction[0][predicted_label] * 100

    print(f"\n{'='*50}")
    print(f"Current image: {current_img_name}")
    print(f"Destination image: {dest_img_name}")
    print(f"Predicted direction: {direction_names[predicted_label]}")
    print(f"Confidence: {confidence:.2f}%")
    print(f"\nAll probabilities:")
    for label, prob in enumerate(prediction[0]):
        print(f"  {direction_names[label]}: {prob*100:.2f}%")
    print(f"{'='*50}")

    return direction_names[predicted_label]

test_prediction('0002_destination.png', '0007_destination.png')

